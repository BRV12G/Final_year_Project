{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNL2moGBBUNeoAwrpZgNH/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRV12G/Final_year_Project/blob/main/fitness_random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGk3Bmrq6UhB",
        "outputId": "e2d9b101-3a6d-4317-af2b-6a8a7055e82e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessing completed!\n",
            "Classification Report for Exercise1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.22      0.20       500\n",
            "           1       0.19      0.19      0.19       510\n",
            "           2       0.19      0.17      0.18       479\n",
            "           3       0.17      0.15      0.16       493\n",
            "           4       0.15      0.15      0.15       463\n",
            "           5       0.13      0.12      0.12       473\n",
            "\n",
            "    accuracy                           0.17      2918\n",
            "   macro avg       0.17      0.17      0.17      2918\n",
            "weighted avg       0.17      0.17      0.17      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Exercise2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.17      0.16       463\n",
            "           1       0.18      0.22      0.20       500\n",
            "           2       0.17      0.15      0.16       493\n",
            "           3       0.13      0.13      0.13       473\n",
            "           4       0.19      0.16      0.17       479\n",
            "           5       0.20      0.19      0.19       510\n",
            "\n",
            "    accuracy                           0.17      2918\n",
            "   macro avg       0.17      0.17      0.17      2918\n",
            "weighted avg       0.17      0.17      0.17      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Exercise3:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.17      0.16       463\n",
            "           1       0.17      0.16      0.16       493\n",
            "           2       0.17      0.21      0.19       500\n",
            "           3       0.19      0.17      0.18       479\n",
            "           4       0.13      0.12      0.13       473\n",
            "           5       0.20      0.19      0.19       510\n",
            "\n",
            "    accuracy                           0.17      2918\n",
            "   macro avg       0.17      0.17      0.17      2918\n",
            "weighted avg       0.17      0.17      0.17      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Equipment1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.20      0.18       465\n",
            "           1       0.16      0.16      0.16       495\n",
            "           2       0.16      0.17      0.16       472\n",
            "           3       0.15      0.15      0.15       503\n",
            "           4       0.14      0.13      0.13       481\n",
            "           5       0.19      0.17      0.18       502\n",
            "\n",
            "    accuracy                           0.16      2918\n",
            "   macro avg       0.16      0.16      0.16      2918\n",
            "weighted avg       0.16      0.16      0.16      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Equipment2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.20      0.18       465\n",
            "           1       0.16      0.16      0.16       503\n",
            "           2       0.19      0.18      0.19       502\n",
            "           3       0.17      0.17      0.17       472\n",
            "           4       0.16      0.15      0.15       495\n",
            "           5       0.14      0.13      0.13       481\n",
            "\n",
            "    accuracy                           0.16      2918\n",
            "   macro avg       0.16      0.16      0.16      2918\n",
            "weighted avg       0.16      0.16      0.16      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for d_vegetables:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.94      0.94       450\n",
            "           1       0.87      0.72      0.79        94\n",
            "           2       0.74      0.82      0.78        87\n",
            "           3       0.95      0.97      0.96      1027\n",
            "           4       0.90      0.91      0.91       182\n",
            "           5       0.90      0.94      0.92       359\n",
            "           6       0.90      0.92      0.91       166\n",
            "           7       0.92      0.88      0.90       161\n",
            "           8       0.93      0.93      0.93       213\n",
            "           9       0.96      0.91      0.93       164\n",
            "          10       1.00      0.07      0.12        15\n",
            "\n",
            "    accuracy                           0.93      2918\n",
            "   macro avg       0.91      0.82      0.83      2918\n",
            "weighted avg       0.93      0.93      0.92      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for d_juice:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.97      0.96      1027\n",
            "           1       0.94      0.94      0.94       346\n",
            "           2       0.92      0.94      0.93       359\n",
            "           3       0.96      0.94      0.95       450\n",
            "           4       0.93      0.90      0.91       181\n",
            "           5       0.95      0.94      0.94       555\n",
            "\n",
            "    accuracy                           0.95      2918\n",
            "   macro avg       0.94      0.94      0.94      2918\n",
            "weighted avg       0.95      0.95      0.95      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for d_proteinintake:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.92      0.91       166\n",
            "           1       0.92      0.89      0.90       161\n",
            "           2       0.95      0.97      0.96      1027\n",
            "           3       0.90      0.94      0.92       359\n",
            "           4       0.90      0.91      0.90       182\n",
            "           5       0.95      0.93      0.94       450\n",
            "           6       0.93      0.92      0.93       213\n",
            "           7       0.92      0.90      0.91       181\n",
            "           8       0.96      0.91      0.93       164\n",
            "           9       1.00      0.07      0.12        15\n",
            "\n",
            "    accuracy                           0.93      2918\n",
            "   macro avg       0.93      0.84      0.84      2918\n",
            "weighted avg       0.93      0.93      0.93      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Accuracy for Exercise1: 0.17\n",
            "Accuracy for Exercise2: 0.17\n",
            "Accuracy for Exercise3: 0.17\n",
            "Accuracy for Equipment1: 0.16\n",
            "Accuracy for Equipment2: 0.16\n",
            "Accuracy for d_vegetables: 0.93\n",
            "Accuracy for d_juice: 0.95\n",
            "Accuracy for d_proteinintake: 0.93\n",
            "\n",
            "Average Accuracy Across Outputs: 0.46\n",
            "Mean Squared Error: 0.6749229313718463\n",
            "R² Score: 0.33097539036783796\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "# Assuming you have the dataset as a CSV file\n",
        "# Replace 'your_dataset.csv' with the actual file path\n",
        "df = pd.read_csv('/content/updated_cleaned_diet_split_exercises.csv')\n",
        "\n",
        "# --------- Preprocessing Categorical Inputs ---------\n",
        "\n",
        "# Label encoding for categorical input columns\n",
        "categorical_inputs = [\n",
        "    'Gender', 'Hypertension', 'Diabetes', 'BMI_Class',\n",
        "    'Fitness_Goal', 'Fitness_Type'\n",
        "]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_inputs:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save the encoder for decoding later\n",
        "\n",
        "# --------- Preprocessing Numeric Inputs ---------\n",
        "\n",
        "# Feature engineering: Calculating BMI (BMI = weight in kg / (height in m)^2)\n",
        "df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)  # Corrected height in cm to meters\n",
        "\n",
        "# Scaling numeric inputs\n",
        "numeric_inputs = ['Age', 'Height', 'Weight', 'BMI', 'Duration_of_Workout']\n",
        "scaler = StandardScaler()\n",
        "df[numeric_inputs] = scaler.fit_transform(df[numeric_inputs])\n",
        "\n",
        "# --------- Preprocessing Categorical Outputs ---------\n",
        "\n",
        "# Encoding categorical output columns\n",
        "categorical_outputs = [\n",
        "    'Exercise1', 'Exercise2', 'Exercise3',\n",
        "    'Equipment1', 'Equipment2',\n",
        "    'd_vegetables', 'd_juice', 'd_proteinintake'\n",
        "]\n",
        "\n",
        "output_label_encoders = {}\n",
        "for col in categorical_outputs:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    output_label_encoders[col] = le\n",
        "\n",
        "# --------- Preprocessing Numeric Outputs ---------\n",
        "\n",
        "# Scaling numeric output columns\n",
        "numeric_outputs = ['Calories_Burnt', 'Water_Intake(Litres)']\n",
        "df[numeric_outputs] = scaler.fit_transform(df[numeric_outputs])\n",
        "\n",
        "# --------- Splitting the Dataset ---------\n",
        "\n",
        "# Define input (X) and output (y) columns\n",
        "input_columns = categorical_inputs + numeric_inputs\n",
        "output_columns = categorical_outputs + numeric_outputs\n",
        "\n",
        "X = df[input_columns]\n",
        "y_categorical = df[categorical_outputs]\n",
        "y_numeric = df[numeric_outputs]\n",
        "# y = df[output_columns]\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Splitting into training and testing sets\n",
        "X_train, X_test, y_train_categorical, y_test_categorical = train_test_split(\n",
        "    X, y_categorical, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "_, _, y_train_numeric, y_test_numeric = train_test_split(\n",
        "    X, y_numeric, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# # --------- Display Processed Data ---------\n",
        "# print(\"Processed Input Features:\")\n",
        "# print(X_train.head())\n",
        "# print(\"\\nProcessed Outputs:\")\n",
        "# print(y_train.head())\n",
        "\n",
        "# Save processed data to CSV files if needed\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "X_test.to_csv('X_test.csv', index=False)\n",
        "# y_train.to_csv('y_train.csv', index=False)\n",
        "# y_test.to_csv('y_test.csv', index=False)\n",
        "y_train_categorical.to_csv('y_train_categorical.csv', index=False)\n",
        "y_test_categorical.to_csv('y_test_categorical.csv', index=False)\n",
        "y_train_numeric.to_csv('y_train_numeric.csv', index=False)\n",
        "y_test_numeric.to_csv('y_test_numeric.csv', index=False)\n",
        "\n",
        "print(\"\\nPreprocessing completed!\")\n",
        "\n",
        "\n",
        "    # Replace `y_train_numeric` with relevant data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "\n",
        "# Define models\n",
        "classifier = MultiOutputClassifier(RandomForestClassifier(random_state=42))\n",
        "regressor = MultiOutputRegressor(RandomForestRegressor(random_state=42))\n",
        "\n",
        "# Fit models\n",
        "classifier.fit(X_train, y_train_categorical)\n",
        "regressor.fit(X_train, y_train_numeric)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Predictions\n",
        "y_pred_categorical = classifier.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "# print(\"Classification Report:\\n\", classification_report(y_test_categorical, y_pred_categorical))\n",
        "\n",
        "# Evaluate each categorical output column\n",
        "for col_idx, col_name in enumerate(y_test_categorical.columns):\n",
        "    print(f\"Classification Report for {col_name}:\\n\")\n",
        "    print(classification_report(\n",
        "        y_test_categorical[col_name],\n",
        "        y_pred_categorical[:, col_idx]  # Predicted values for this column\n",
        "    ))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracies = []\n",
        "for col_idx, col_name in enumerate(y_test_categorical.columns):\n",
        "    acc = accuracy_score(y_test_categorical[col_name], y_pred_categorical[:, col_idx])\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Accuracy for {col_name}: {acc:.2f}\")\n",
        "\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"\\nAverage Accuracy Across Outputs: {average_accuracy:.2f}\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Predictions\n",
        "y_pred_numeric = regressor.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "mse = mean_squared_error(y_test_numeric, y_pred_numeric)\n",
        "r2 = r2_score(y_test_numeric, y_pred_numeric)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R² Score:\", r2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/updated_cleaned_diet_split_exercises.csv')\n",
        "\n",
        "# --------- Preprocessing Categorical Inputs ---------\n",
        "categorical_inputs = [\n",
        "    'Gender', 'Hypertension', 'Diabetes', 'BMI_Class',\n",
        "    'Fitness_Goal', 'Fitness_Type'\n",
        "]\n",
        "\n",
        "label_encoders = {}\n",
        "for col in categorical_inputs:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    label_encoders[col] = le  # Save the encoder for decoding later\n",
        "\n",
        "# --------- Preprocessing Numeric Inputs ---------\n",
        "df['BMI'] = df['Weight'] / ((df['Height'] / 100) ** 2)  # Corrected height in cm to meters\n",
        "\n",
        "numeric_inputs = ['Age', 'Height', 'Weight', 'BMI', 'Duration_of_Workout']\n",
        "scaler = StandardScaler()\n",
        "df[numeric_inputs] = scaler.fit_transform(df[numeric_inputs])\n",
        "\n",
        "# --------- Preprocessing Categorical Outputs ---------\n",
        "categorical_outputs = [\n",
        "    'Exercise1', 'Exercise2', 'Exercise3',\n",
        "    'Equipment1', 'Equipment2',\n",
        "    'd_vegetables', 'd_juice', 'd_proteinintake'\n",
        "]\n",
        "\n",
        "output_label_encoders = {}\n",
        "for col in categorical_outputs:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    output_label_encoders[col] = le\n",
        "\n",
        "# --------- Preprocessing Numeric Outputs ---------\n",
        "numeric_outputs = ['Calories_Burnt', 'Water_Intake(Litres)']\n",
        "df[numeric_outputs] = scaler.fit_transform(df[numeric_outputs])\n",
        "\n",
        "# --------- Splitting the Dataset ---------\n",
        "input_columns = categorical_inputs + numeric_inputs\n",
        "output_columns = categorical_outputs + numeric_outputs\n",
        "\n",
        "X = df[input_columns]\n",
        "y_categorical = df[categorical_outputs]\n",
        "y_numeric = df[numeric_outputs]\n",
        "\n",
        "X_train, X_test, y_train_categorical, y_test_categorical = train_test_split(\n",
        "    X, y_categorical, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "_, _, y_train_numeric, y_test_numeric = train_test_split(\n",
        "    X, y_numeric, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --------- Model Definitions ---------\n",
        "# Define models with hyperparameter tuning options\n",
        "classifier = MultiOutputClassifier(\n",
        "    RandomForestClassifier(\n",
        "        random_state=42,\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=4\n",
        "    )\n",
        ")\n",
        "\n",
        "regressor = MultiOutputRegressor(\n",
        "    RandomForestRegressor(\n",
        "        random_state=42,\n",
        "        n_estimators=100,\n",
        "        max_depth=10,\n",
        "        min_samples_split=4\n",
        "    )\n",
        ")\n",
        "\n",
        "# --------- Hyperparameter Tuning Using GridSearchCV ---------\n",
        "# For the classifier\n",
        "param_grid_classifier = {\n",
        "    'estimator__n_estimators': [100, 200, 300],\n",
        "    'estimator__max_depth': [10, 20, None],\n",
        "    'estimator__min_samples_split': [2, 4, 6]\n",
        "}\n",
        "\n",
        "grid_search_classifier = GridSearchCV(\n",
        "    classifier, param_grid_classifier, cv=3, n_jobs=-1, scoring='accuracy'\n",
        ")\n",
        "grid_search_classifier.fit(X_train, y_train_categorical)\n",
        "\n",
        "# For the regressor\n",
        "param_grid_regressor = {\n",
        "    'estimator__n_estimators': [100, 200, 300],\n",
        "    'estimator__max_depth': [10, 20, None],\n",
        "    'estimator__min_samples_split': [2, 4, 6]\n",
        "}\n",
        "\n",
        "grid_search_regressor = GridSearchCV(\n",
        "    regressor, param_grid_regressor, cv=3, n_jobs=-1, scoring='neg_mean_squared_error'\n",
        ")\n",
        "grid_search_regressor.fit(X_train, y_train_numeric)\n",
        "\n",
        "# --------- Model Evaluation ---------\n",
        "# Best model after grid search for classifier and regressor\n",
        "classifier_best = grid_search_classifier.best_estimator_\n",
        "regressor_best = grid_search_regressor.best_estimator_\n",
        "\n",
        "# Predictions\n",
        "y_pred_categorical = classifier_best.predict(X_test)\n",
        "y_pred_numeric = regressor_best.predict(X_test)\n",
        "\n",
        "# --------- Classification Evaluation ---------\n",
        "for col_idx, col_name in enumerate(y_test_categorical.columns):\n",
        "    print(f\"Classification Report for {col_name}:\\n\")\n",
        "    print(classification_report(\n",
        "        y_test_categorical[col_name],\n",
        "        y_pred_categorical[:, col_idx]  # Predicted values for this column\n",
        "    ))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Calculate accuracy for each column\n",
        "accuracies = []\n",
        "for col_idx, col_name in enumerate(y_test_categorical.columns):\n",
        "    acc = accuracy_score(y_test_categorical[col_name], y_pred_categorical[:, col_idx])\n",
        "    accuracies.append(acc)\n",
        "    print(f\"Accuracy for {col_name}: {acc:.2f}\")\n",
        "\n",
        "average_accuracy = np.mean(accuracies)\n",
        "print(f\"\\nAverage Accuracy Across Outputs: {average_accuracy:.2f}\")\n",
        "\n",
        "# --------- Regression Evaluation ---------\n",
        "mse = mean_squared_error(y_test_numeric, y_pred_numeric)\n",
        "r2 = r2_score(y_test_numeric, y_pred_numeric)\n",
        "\n",
        "print(\"\\nMean Squared Error:\", mse)\n",
        "print(\"R² Score:\", r2)\n",
        "\n",
        "# --------- Cross-validation ---------\n",
        "cross_val_score_classifier = cross_val_score(classifier_best, X, y_categorical, cv=3, scoring='accuracy')\n",
        "cross_val_score_regressor = cross_val_score(regressor_best, X, y_numeric, cv=3, scoring='neg_mean_squared_error')\n",
        "\n",
        "print(f\"Cross-Validation Accuracy (Classifier): {np.mean(cross_val_score_classifier):.2f}\")\n",
        "print(f\"Cross-Validation R² (Regressor): {np.mean(cross_val_score_regressor):.2f}\")\n",
        "\n",
        "# --------- Save processed data ---------\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "X_test.to_csv('X_test.csv', index=False)\n",
        "y_train_categorical.to_csv('y_train_categorical.csv', index=False)\n",
        "y_test_categorical.to_csv('y_test_categorical.csv', index=False)\n",
        "y_train_numeric.to_csv('y_train_numeric.csv', index=False)\n",
        "y_test_numeric.to_csv('y_test_numeric.csv', index=False)\n",
        "\n",
        "print(\"\\nPreprocessing and model training completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TGgom9w25un",
        "outputId": "bb19de45-5416-472d-d4c4-ccff344eebd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:1107: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Exercise1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.30      0.22       500\n",
            "           1       0.16      0.16      0.16       510\n",
            "           2       0.17      0.11      0.14       479\n",
            "           3       0.15      0.10      0.12       493\n",
            "           4       0.15      0.12      0.13       463\n",
            "           5       0.16      0.18      0.17       473\n",
            "\n",
            "    accuracy                           0.16      2918\n",
            "   macro avg       0.16      0.16      0.16      2918\n",
            "weighted avg       0.16      0.16      0.16      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Exercise2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.12      0.13       463\n",
            "           1       0.17      0.30      0.22       500\n",
            "           2       0.15      0.10      0.12       493\n",
            "           3       0.16      0.18      0.17       473\n",
            "           4       0.17      0.11      0.14       479\n",
            "           5       0.16      0.16      0.16       510\n",
            "\n",
            "    accuracy                           0.16      2918\n",
            "   macro avg       0.16      0.16      0.16      2918\n",
            "weighted avg       0.16      0.16      0.16      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Exercise3:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.12      0.13       463\n",
            "           1       0.15      0.10      0.12       493\n",
            "           2       0.17      0.30      0.22       500\n",
            "           3       0.17      0.11      0.14       479\n",
            "           4       0.16      0.18      0.17       473\n",
            "           5       0.16      0.16      0.16       510\n",
            "\n",
            "    accuracy                           0.16      2918\n",
            "   macro avg       0.16      0.16      0.16      2918\n",
            "weighted avg       0.16      0.16      0.16      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Equipment1:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.22      0.19       465\n",
            "           1       0.18      0.18      0.18       495\n",
            "           2       0.17      0.17      0.17       472\n",
            "           3       0.17      0.17      0.17       503\n",
            "           4       0.16      0.16      0.16       481\n",
            "           5       0.16      0.11      0.13       502\n",
            "\n",
            "    accuracy                           0.17      2918\n",
            "   macro avg       0.17      0.17      0.17      2918\n",
            "weighted avg       0.17      0.17      0.17      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for Equipment2:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.22      0.19       465\n",
            "           1       0.17      0.17      0.17       503\n",
            "           2       0.16      0.11      0.13       502\n",
            "           3       0.17      0.17      0.17       472\n",
            "           4       0.18      0.18      0.18       495\n",
            "           5       0.16      0.16      0.16       481\n",
            "\n",
            "    accuracy                           0.17      2918\n",
            "   macro avg       0.17      0.17      0.17      2918\n",
            "weighted avg       0.17      0.17      0.17      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for d_vegetables:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.93      0.93       450\n",
            "           1       0.94      0.71      0.81        94\n",
            "           2       0.72      0.84      0.78        87\n",
            "           3       0.93      0.96      0.95      1027\n",
            "           4       0.91      0.90      0.91       182\n",
            "           5       0.89      0.92      0.91       359\n",
            "           6       0.90      0.91      0.90       166\n",
            "           7       0.91      0.87      0.89       161\n",
            "           8       0.90      0.93      0.91       213\n",
            "           9       0.96      0.90      0.93       164\n",
            "          10       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.92      2918\n",
            "   macro avg       0.82      0.81      0.81      2918\n",
            "weighted avg       0.91      0.92      0.91      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for d_juice:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95      1027\n",
            "           1       0.92      0.90      0.91       346\n",
            "           2       0.89      0.92      0.91       359\n",
            "           3       0.94      0.94      0.94       450\n",
            "           4       0.90      0.88      0.89       181\n",
            "           5       0.92      0.92      0.92       555\n",
            "\n",
            "    accuracy                           0.93      2918\n",
            "   macro avg       0.92      0.92      0.92      2918\n",
            "weighted avg       0.93      0.93      0.93      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Classification Report for d_proteinintake:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.91      0.90       166\n",
            "           1       0.91      0.87      0.89       161\n",
            "           2       0.94      0.95      0.95      1027\n",
            "           3       0.90      0.93      0.91       359\n",
            "           4       0.91      0.90      0.90       182\n",
            "           5       0.94      0.93      0.93       450\n",
            "           6       0.90      0.93      0.92       213\n",
            "           7       0.91      0.87      0.89       181\n",
            "           8       0.95      0.90      0.92       164\n",
            "           9       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.92      2918\n",
            "   macro avg       0.82      0.82      0.82      2918\n",
            "weighted avg       0.92      0.92      0.92      2918\n",
            "\n",
            "--------------------------------------------------\n",
            "Accuracy for Exercise1: 0.16\n",
            "Accuracy for Exercise2: 0.16\n",
            "Accuracy for Exercise3: 0.16\n",
            "Accuracy for Equipment1: 0.17\n",
            "Accuracy for Equipment2: 0.17\n",
            "Accuracy for d_vegetables: 0.92\n",
            "Accuracy for d_juice: 0.93\n",
            "Accuracy for d_proteinintake: 0.92\n",
            "\n",
            "Average Accuracy Across Outputs: 0.45\n",
            "\n",
            "Mean Squared Error: 0.6475083027789974\n",
            "R² Score: 0.3581638247946875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 118, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: multiclass-multioutput is not supported\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 118, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: multiclass-multioutput is not supported\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:978: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 140, in __call__\n",
            "    score = scorer._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 388, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 216, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 227, in accuracy_score\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 118, in _check_targets\n",
            "    raise ValueError(\"{0} is not supported\".format(y_type))\n",
            "ValueError: multiclass-multioutput is not supported\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Accuracy (Classifier): nan\n",
            "Cross-Validation R² (Regressor): -0.64\n",
            "\n",
            "Preprocessing and model training completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.utils import class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset (adjust path as necessary)\n",
        "df = pd.read_csv('/content/updated_cleaned_diet_split_exercises.csv')\n",
        "\n",
        "# Handle missing values using SimpleImputer\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Define features and target variables\n",
        "X = df_imputed.drop(['Exercise1', 'Exercise2', 'Exercise3', 'Equipment1', 'Equipment2', 'd_vegetables', 'd_juice', 'd_proteinintake'], axis=1)\n",
        "y = df_imputed[['Exercise1', 'Exercise2', 'Exercise3', 'Equipment1', 'Equipment2', 'd_vegetables', 'd_juice', 'd_proteinintake']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE for handling class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_smote)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define parameter grid for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Perform RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train_scaled, y_train_smote)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = best_rf.predict(X_test_scaled)\n",
        "\n",
        "# Classification Report for each output (Exercise1, Exercise2, Exercise3, etc.)\n",
        "for column in y.columns:\n",
        "    print(f\"Classification Report for {column}:\\n\")\n",
        "    print(classification_report(y_test[column], y_pred[:, y.columns.get_loc(column)]))\n",
        "    print('-' * 50)\n",
        "\n",
        "# Overall accuracy for each output\n",
        "for column in y.columns:\n",
        "    accuracy = accuracy_score(y_test[column], y_pred[:, y.columns.get_loc(column)])\n",
        "    print(f\"Accuracy for {column}: {accuracy:.2f}\")\n",
        "\n",
        "# Overall model performance (Accuracy, Mean Squared Error, and R² Score)\n",
        "avg_accuracy = accuracy_score(y_test, y_pred)  # Overall accuracy\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nAverage Accuracy Across Outputs: {avg_accuracy:.2f}\")\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "\n",
        "# Optionally, handle class weights for RandomForestClassifier if the imbalance is still present\n",
        "# class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_smote), y=y_train_smote)\n",
        "# rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "tkyYGaM2Bces",
        "outputId": "67b1356d-ef64-4e64-821d-77e782105300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'Male'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-2aa59360a5d0>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Handle missing values using SimpleImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf_imputed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Define features and target variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \"\"\"\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/impute/_base.py\u001b[0m in \u001b[0;36m_validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    359\u001b[0m                     )\n\u001b[1;32m    360\u001b[0m                 )\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mnew_ve\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'Male'"
          ]
        }
      ]
    }
  ]
}