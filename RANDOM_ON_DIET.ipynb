{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON3YG1tn++rDnmN3DvoNJP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BRV12G/Final_year_Project/blob/main/RANDOM_ON_DIET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYWv1s4RNH12",
        "outputId": "b7b3c4fb-4f29-47cf-8aa1-e9fc131b7eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-04af9a13e689>:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[column].fillna(data[column].mode()[0], inplace=True)\n",
            "<ipython-input-2-04af9a13e689>:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[column].fillna(data[column].mean(), inplace=True)\n",
            "<ipython-input-2-04af9a13e689>:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['Gender'] = X['Gender'].map({'Male': 0, 'Female': 1})\n",
            "<ipython-input-2-04af9a13e689>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoders[col].fit_transform(X[col])\n",
            "<ipython-input-2-04af9a13e689>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoders[col].fit_transform(X[col])\n",
            "<ipython-input-2-04af9a13e689>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoders[col].fit_transform(X[col])\n",
            "<ipython-input-2-04af9a13e689>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoders[col].fit_transform(X[col])\n",
            "<ipython-input-2-04af9a13e689>:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = label_encoders[col].fit_transform(X[col])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 5.2356418397785545\n",
            "Mean Squared Error (MSE): 395.89496004723514\n",
            "RÂ² Score: 0.9888964531360311\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['random_forest_multioutput_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# https://chatgpt.com/share/6777a062-0100-800b-bbbd-5f34af0add9f\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load dataset\n",
        "# Replace 'file_path.csv' with your actual dataset file path\n",
        "data = pd.read_csv('/content/nutrition_dataset_with_fiber_water_intake (1).csv')\n",
        "\n",
        "# 1. Drop 'Person ID' and 'Health Status' columns\n",
        "data = data.drop(columns=['Person ID', 'Health Status'])\n",
        "\n",
        "# 2. Check for missing values and handle them\n",
        "# Fill missing numerical values with the mean, and categorical values with the mode\n",
        "for column in data.columns:\n",
        "    if data[column].dtype == 'object':\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "    else:\n",
        "        data[column].fillna(data[column].mean(), inplace=True)\n",
        "\n",
        "# 3. Handle outliers using the IQR method\n",
        "def handle_outliers(df, columns):\n",
        "    for col in columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        df[col] = np.clip(df[col], lower_bound, upper_bound)\n",
        "    return df\n",
        "\n",
        "numerical_columns = [\n",
        "    'Age', 'Sleep Duration', 'Weight (kg)', 'Height (cm)', 'Systolic',\n",
        "    'Diastolic', 'Heart Rate', 'Daily Steps', 'BMI Values'\n",
        "]\n",
        "data = handle_outliers(data, numerical_columns)\n",
        "\n",
        "# Separate inputs and outputs\n",
        "input_columns = numerical_columns + [\n",
        "    'Gender', 'Occupation', 'Quality of Sleep', 'Activity Level',\n",
        "    'Stress Level', 'Blood Pressure Category', 'BMI Class'\n",
        "]\n",
        "output_columns = [\n",
        "    'Calories (kcal)', 'Carbohydrates (g)', 'Proteins (g)', 'Fats (g)',\n",
        "    'Vitamin A (mcg)', 'Vitamin C (mg)', 'Vitamin D (mcg)', 'Sodium (mg)',\n",
        "    'Potassium (mg)', 'Magnesium (mg)', 'Iron (mg)', 'Zinc (mg)',\n",
        "    'Fiber Intake (g)', 'Water Intake (L)'\n",
        "]\n",
        "X = data[input_columns]\n",
        "y = data[output_columns]\n",
        "\n",
        "# 4. Preprocess categorical and numerical data\n",
        "# Binary encode Gender\n",
        "X['Gender'] = X['Gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "# Label encode categorical columns\n",
        "label_columns = ['Quality of Sleep', 'Activity Level', 'Stress Level', 'Blood Pressure Category', 'BMI Class']\n",
        "label_encoders = {col: LabelEncoder() for col in label_columns}\n",
        "for col in label_columns:\n",
        "    X[col] = label_encoders[col].fit_transform(X[col])\n",
        "\n",
        "# One-hot encode Occupation\n",
        "X = pd.get_dummies(X, columns=['Occupation'], drop_first=True)\n",
        "\n",
        "# Standardize and normalize numerical columns\n",
        "scaler = Pipeline(steps=[\n",
        "    ('standardize', StandardScaler()),\n",
        "    ('normalize', MinMaxScaler())\n",
        "])\n",
        "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
        "\n",
        "# 5. Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Train the model using Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "multioutput_model = MultiOutputRegressor(rf_model)\n",
        "multioutput_model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Evaluate the model\n",
        "y_pred = multioutput_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
        "print(\"RÂ² Score:\", r2_score(y_test, y_pred))\n",
        "\n",
        "# 8. Save the model for later use\n",
        "import joblib\n",
        "joblib.dump(multioutput_model, 'random_forest_multioutput_model.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGclFHTpSroz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}